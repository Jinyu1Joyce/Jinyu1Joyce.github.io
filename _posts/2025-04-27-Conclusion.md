---
layout: post
title: Conclusion
comments: true
mathjax: true
---
In this research, we leveraged a dual–model, zero-shot classification pipeline to uncover structural biases in Meta’s loan ads delivery system within the French market. By computing normalized exposure ratios both before and after aggregating semantically similar ads, we demonstrated that algorithmic amplification can mask and even reverse apparent targeting patterns. While unaggregated data suggested a male bias in exposure to harmful and fraudulent loan ads, aggregation revealed that women—particularly those aged 18 – 24 and 45 – 54—are in fact over-exposed once delivery algorithms fold in engagement signals. This discrepancy highlights the platform’s active role in shaping information access, rather than passively filtering advertiser intent.

Our findings raise urgent questions about fairness and transparency in personalized advertising, especially for high-risk financial products. They underscore the need for regulatory safeguards—such as clearer GDPR disclosures and DSA-mandated risk assessments—to hold algorithmic systems accountable. Future research should enhance detection by incorporating multimodal cues and calibrated thresholds, expand beyond zero-shot methods with domain-specific fine-tuning, and evaluate real-world impacts on user financial behavior and well-being.
