---
layout: post
title: Executive Summary 
comments: true
mathjax: true
---

This study conducts a systematic analysis of algorithmic bias in the delivery of loan advertisements on Meta’s platform in France, with a focus on whether users of different gender and age groups experience unequal exposure to high-risk or potentially fraudulent financial content. Drawing on Meta’s Ad Library data from October 2024, we employed two pre-trained natural language inference models: mDeBERTa and BART in a zero-shot classification framework to identify and label harmful and fraudulent loan advertisements.

Out of 269 loan advertisements analyzed, a substantial number were found to carry financial risk and were classified as fraud. Through normalized exposure analysis at both aggregated and disaggregated levels, we uncovered significant demographic discrepancies in ad delivery. While initial data showed higher exposure among male users, aggregated results revealed that women, especially those aged 18–24 and 45–54, were disproportionately targeted. These patterns suggest that Meta’s ad delivery system is influenced not solely by advertiser intent, but by algorithmic feedback loops that reinforce prior engagement, amplifying exposure among already vulnerable groups. Such findings raise concerns about potential non-compliance with the fairness, transparency, and risk mitigation principles mandated under the Digital Services Act (DSA) and the General Data Protection Regulation (GDPR). 
