---
layout: post
title: Literature review
subtitle: Unmasking Harmful Loan Ads
cover-img: /assets/img/2.2.jpg.webp
thumbnail-img: /assets/img/2.1.jpeg
share-img: /assets/img/2.2.jpg.webp
---


In today’s increasingly complex digital financial environment, the boundary between financial fraud and financial risk is becoming increasingly blurred. These two issues often overlap, posing significant threats to consumer financial security and undermining market fairness. In academic literature, **financial fraud** is commonly defined as 
>a deliberate act of deception aimed at obtaining illicit gains through the manipulation of information or exploitation of system vulnerabilities (Button et al., 2014).

However, there remains no consistent academic consensus on how to define specific types of fraud. As a result, the classification and identification of financial risks in practice are often shaped by the categorizations and warnings issued by government regulatory agencies. 

For instance, the New York State Department of Financial Services classifies **high-risk financial products** into several types of predatory loans and loan scams, including **_payday loans_**, **_tax refund anticipation loans_**, **_advance fee loan scams_**, and **_government grant loan scams_**. These products are frequently marketed using language such as **_“instant approval”_** or **_“no credit check,”_** yet they are commonly associated with extremely **_high annual percentage rates (APRs)_**, **_false promises_**, **_identity theft_**, and **_upfront payment scams_**. Similarly, the European Financial Inclusion Network Working Group on Over-Indebtedness (2016) defines **unfair lending practices** as those that **_involve a lack of creditworthiness assessment or inadequate disclosure of key terms_**, and identifies **_payday loans_** and **_foreign currency loans_** as “toxic loans” due to their high costs and currency fluctuation risks, which can easily trap borrowers in long-term cycles of default.

In terms of risk identification and consumer protection, the U.S. Consumer Financial Protection Bureau (CFPB) highlights the need to be especially cautious of high-risk features hidden in loan agreements, such as **_prepayment penalties_**, **_balloon payments_**, **_negative amortization_**, and **_interest-only structures_**. These features may lead to unexpected costs during the loan term and increase the likelihood of borrower default. Together, these regulatory categorizations provide a structured basis for defining and applying “financial risk” labels in the context of our analysis.


In the field of financial risk and fraud detection, machine learning techniques have been widely used to identify fraudulent behavior in large-scale datasets. Almarhabi et al. (2023) applied supervised machine learning methods—including Random Forest, Logistic Regression, and Naive Bayes to detect cryptocurrency fraud in the U.S. context, with the Random Forest model achieving near-perfect accuracy. However, their approach heavily relies on pre-labeled data and is therefore limited to detecting known fraud patterns. It struggles to identify novel or more covert forms of fraud. Moreover, the study focused solely on structured transactional data and did not address natural language processing (NLP) tasks, making it unsuitable for analyzing risky language in advertising or social media, especially in multilingual contexts.

Similarly, Rana et al. (2022) employed a pre-trained BERT language model to detect fraudulent job postings and achieved outstanding performance under a supervised learning setting (with an F1-score of 0.93). While their model benefited from BERT’s strong contextual understanding, it still required extensive human-labeled data for fine-tuning, which limits its applicability to emerging or subtle fraud schemes. Furthermore, since their dataset consisted of structured recruitment texts, the model lacked adaptability to unstructured advertising content and did not support multilingual analysis—factors essential to our study on cross-language ad-based risk detection.

Kuo and Tsang (2024) proposed a hybrid approach combining emotion analysis with supervised learning to identify investment scams. They extracted emotional fluctuation features across different scam lifecycle stages from Chinese chatroom data and applied classifiers such as Support Vector Machine, Decision Tree, and Random Tree. Although their findings demonstrated a strong correlation between emotional trajectories and scam-related language, the model’s dependence on a predefined Chinese emotion lexicon and structured dialogue data limits its ability to generalize to multilingual, semantically complex advertising texts. As such, it is not applicable to our research objectives.

__
In recent years, **zero-shot text classification** has emerged as an effective solution to the challenge of limited labeled data in natural language processing. Yin et al. (2019) proposed reframing text classification as a natural language inference (NLI) task, where the input text is treated as the premise and each candidate label is reformulated as a hypothesis. The NLI model then estimates the probability of the label being true by evaluating whether the premise entails the hypothesis. This approach enables cross-task classification without the need for task-specific fine-tuning.

The **multilingual mDeBERTa model**, which supports semantic reasoning across more than 100 languages, is particularly well-suited to the analysis of digital advertisements in highly multilingual environments. At the same time, **BART, a sequence-to-sequence Transformer model proposed by Facebook**, has demonstrated strong performance in NLI-based zero-shot settings. In particular, the version fine-tuned on the MNLI dataset, facebook/bart-large-mnli, has been widely adopted in high-risk text classification scenarios such as financial fraud detection. Compared to prompt-based models like GPT, BART offers a more structured and template-free classification approach, making it easier to deploy and adapt. 

Therefore, in our study, **we will apply a zero-shot text classification pipeline to analyze loan-related advertisements from Meta’s ad library, using the mDeBERTa model to detect financial risk content without the need for labeled training data, and leveraging facebook/bart-large-mnli to assess whether an ad is potentially fraudulent**. This approach is based on a premise–hypothesis structure that simulates human reasoning and aligns with value-oriented analytical frameworks commonly used in the social sciences. As such, it is particularly effective in identifying value-laden textual content such as financial scams, misleading promotions, and emotional manipulation. Moreover, the model’s adaptability to multilingual contexts and complex text structures makes it a highly efficient and flexible tool for detecting financial risk in multilingual digital advertising across diverse platforms.

<summary>Click here!</summary>
Here you can see an **expandable** section
</details>
